{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build local BLAST database\n",
    "#### only need to build once. Ignore this part if you have performed this before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## change the name of genes that is going to be built into local database\n",
    "gene_names = ['RBCL']\n",
    "\n",
    "for gene_name in gene_names:\n",
    "    path_fastafile = 'GbRefgene/gb'+gene_name+'.fasta'\n",
    "    dbtitle = gene_name+'ref'\n",
    "    !makeblastdb -in {path_fastafile} -parse_seqids -title {dbtitle} -dbtype nucl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Input Query filename and RefGene name\n",
    "fasta file of sequencing reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 sample files in directory: InputData\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = 'InputData'  # change input files directory\n",
    "\n",
    "fastq_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "fastq_files = [path.splitext(x)[0] for x in fastq_files]\n",
    "\n",
    "print('Found %d sample files in directory: %s' % (len(fastq_files), mypath))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dereplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsearch v2.15.1_linux_x86_64, 15.5GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file InputData/054717_34_S141_run899.fastq 100%  \n",
      "11431127 nt in 74027 seqs, min 36, max 167, avg 154\n",
      "Sorting 100%\n",
      "1694 unique sequences, avg cluster 43.7, median 1, max 46595\n",
      "Writing output file 100% \n",
      "vsearch v2.15.1_linux_x86_64, 15.5GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file InputData/055130_89_S105_run905.fastq 100%  \n",
      "2635739 nt in 9907 seqs, min 35, max 489, avg 266\n",
      "Sorting 100%\n",
      "2752 unique sequences, avg cluster 3.6, median 1, max 586\n",
      "Writing output file 100%   \n"
     ]
    }
   ],
   "source": [
    "#fastq_files = ['Deer32']\n",
    "#uncomment to manually input sample filenames without file extension\n",
    "\n",
    "for eachfastq in fastq_files:\n",
    "    !vsearch --derep_fulllength {mypath}/{eachfastq}.fastq --output {mypath}/{eachfastq}_derep.fasta --sizeout --relabel uniq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsearch v2.15.1_linux_x86_64, 15.5GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Reading file InputData/054717_34_S141_run899_derep.fasta 100%  \n",
      "2705 nt in 20 seqs, min 40, max 157, avg 135\n",
      "minsize 50: 1674 sequences discarded.\n",
      "Masking 100% \n",
      "Sorting by abundance 100%\n",
      "Counting k-mers 100% \n",
      "Clustering 100%  \n",
      "Sorting clusters 100%\n",
      "Writing clusters 100% \n",
      "Clusters: 11 Size min 1, max 9, avg 1.8\n",
      "Singletons: 9, 45.0% of seqs, 81.8% of clusters\n",
      "vsearch v2.15.1_linux_x86_64, 15.5GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Reading file InputData/055130_89_S105_run905_derep.fasta 100%  \n",
      "8234 nt in 25 seqs, min 41, max 488, avg 329\n",
      "minsize 50: 2727 sequences discarded.\n",
      "Masking 100% \n",
      "Sorting by abundance 100%\n",
      "Counting k-mers 100% \n",
      "Clustering 100%   \n",
      "Sorting clusters 100%\n",
      "Writing clusters 100% \n",
      "Clusters: 24 Size min 1, max 2, avg 1.0\n",
      "Singletons: 23, 92.0% of seqs, 95.8% of clusters\n"
     ]
    }
   ],
   "source": [
    "min_read_num = 50\n",
    "\n",
    "for eachfastq in fastq_files:\n",
    "    !vsearch --cluster_unoise {mypath}/{eachfastq}_derep.fasta --minsize {min_read_num} --unoise_alpha 2 --centroids {mypath}/{eachfastq}_freqfilt.fasta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_files = ['Deer32']\n",
    "# uncomment to manually change the filenames\n",
    "query_files = fastq_files\n",
    "\n",
    "gene_names = ['RBCL']\n",
    "# change the list of genes that is gonna be blasted upon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Blast against Local Reference Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blasting 054717_34_S141_run899 against RBCL database... Completed. Runtime:  0:00:00.489157\n",
      "\n",
      "\n",
      "mkdir: cannot create directory ‘055130_89_S105_run905_blastResults’: File exists\n",
      "\n",
      "Blasting 055130_89_S105_run905 against RBCL database... Completed. Runtime:  0:00:01.038178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_identity = 98   ## change the limit\n",
    "alignment_length = 100   ## > 50 bp must be aligned\n",
    "\n",
    "\n",
    "for query_file in query_files:\n",
    "\n",
    "    !mkdir {query_file}_blastResults\n",
    "\n",
    "    path_blastin = mypath+'/'+query_file+'_freqfilt.fasta'\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        \n",
    "        path_fastafile = 'GbRefgene/gb'+gene_name+'.fasta'\n",
    "        path_blastout  = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'.tsv'\n",
    "        \n",
    "        blastx_cline = NcbiblastnCommandline(query=path_blastin, db=path_fastafile, evalue=0.001, line_length=alignment_length, perc_identity=percent_identity, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=path_blastout)\n",
    "        print('\\nBlasting '+query_file+' against', gene_name, 'database...', end=\" \")\n",
    "        t0 = datetime.now()\n",
    "        stdout, stderr = blastx_cline()\n",
    "        t1 = datetime.now()\n",
    "        print('Completed. Runtime: ', t1 - t0)\n",
    "\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parse Blast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = 054717_34_S141_run899\n",
      "Parsing blast RBCL result...\n",
      "\t Number of reads with hits = 9\n",
      "\t Hit_Count: Homo_sapiens = 0 \t Bacteria = 0 \t Fungi = 0\n",
      "\n",
      "\n",
      "Query File = 055130_89_S105_run905\n",
      "Parsing blast RBCL result...\n",
      "\t Number of reads with hits = 11\n",
      "\t Hit_Count: Homo_sapiens = 0 \t Bacteria = 0 \t Fungi = 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        blastn = pd.read_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'.tsv', sep='\\t', header=None)\n",
    "        blastn.columns = 'qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore'.split(' ')\n",
    "\n",
    "        reads = set(blastn['qseqid'])\n",
    "        print('Parsing blast ' + gene_name + ' result...')\n",
    "        print('\\t Number of reads with hits =', len(reads))\n",
    "\n",
    "\n",
    "        neitheridx = []\n",
    "        read_freq = []\n",
    "\n",
    "\n",
    "        ## filter hits if it belongs to human, bacteria, or fungi\n",
    "        for idx, eachrow in blastn.iterrows():\n",
    "            if (idx+1) % 100000 == 0:    print(idx)\n",
    "\n",
    "            m = re.search(';size=(\\d+)', eachrow['qseqid'])\n",
    "            read_count = m.group(1)\n",
    "            read_freq.append(read_count)\n",
    "\n",
    "            ## The presence of human, bacteria or fungi DNA could indicate contamination\n",
    "            ## The interpretation varies according to the samples\n",
    "            contaminate_count = [0, 0, 0]\n",
    "            if 'Homo_sapiens' in eachrow['stitle']:\n",
    "                contaminate_count[0] += 1\n",
    "            elif 'Bacteria' in eachrow['stitle']:\n",
    "                contaminate_count[1] += 1\n",
    "            elif 'Fungi' in eachrow['stitle']:\n",
    "                contaminate_count[2] += 1\n",
    "            else:\n",
    "                neitheridx.append(idx)\n",
    "\n",
    "        print(\"\\t Hit_Count: Homo_sapiens = %d \\t Bacteria = %d \\t Fungi = %d\" % (contaminate_count[0], contaminate_count[1], contaminate_count[2]))\n",
    "\n",
    "\n",
    "\n",
    "        ## retrieve frequency information\n",
    "        blastn['read_freq'] = read_freq\n",
    "        subset = blastn.loc[neitheridx, :]\n",
    "\n",
    "\n",
    "\n",
    "        ## retrieve read sequence from query_file\n",
    "        qseqids = list(set(list(subset['qseqid'])))\n",
    "        qseqdict = dict()\n",
    "\n",
    "        path_blastin = mypath+'/'+query_file+'_freqfilt.fasta'\n",
    "        zipfa = SeqIO.parse(path_blastin, 'fasta')\n",
    "        for read in zipfa:\n",
    "            if read.id in qseqids:\n",
    "                qseqdict[read.id] = read.seq\n",
    "\n",
    "        qseqs = []\n",
    "        for idx, eachrow in subset.iterrows():\n",
    "            qseqs.append(str(qseqdict[eachrow['qseqid']]))\n",
    "        subset['qseq'] = qseqs\n",
    "        subset.to_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'_filtered.tsv', sep='\\t')\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Top identity hit for each read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = 054717_34_S141_run899\n",
      "Extract top hits of blast result\n",
      "\t Extracting gene RBCL ...\n",
      "\t Completed\n",
      "\n",
      "Query File = 055130_89_S105_run905\n",
      "Extract top hits of blast result\n",
      "\t Extracting gene RBCL ...\n",
      "\t Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    print('Extract top hits of blast result')\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        print('\\t Extracting gene', gene_name, '...')\n",
    "        \n",
    "        path_blastin = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'_filtered.tsv'\n",
    "        #if not path.exists(path_blastin):    continue\n",
    "        ident = pd.read_csv(path_blastin, sep='\\t', index_col=0)\n",
    "\n",
    "        qseqids = []\n",
    "        topidenIdx = []\n",
    "\n",
    "        prev_qseqid = ''\n",
    "\n",
    "        for idx, eachrow in ident.iterrows():\n",
    "            qseqid = eachrow['qseqid']\n",
    "\n",
    "            if qseqid != prev_qseqid:\n",
    "                prev_qseqid = qseqid\n",
    "                topident = eachrow['pident']\n",
    "                topidenIdx.append(idx)\n",
    "\n",
    "            else:\n",
    "                if eachrow['pident'] == topident:\n",
    "                    topidenIdx.append(idx)\n",
    "        \n",
    "        ident.loc[topidenIdx, :].to_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'-topIden.tsv', sep='\\t')\n",
    "\n",
    "    print('\\t Completed\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Diet Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = 054717_34_S141_run899\n",
      "Counting species from top identity hits...\n",
      "\t Counting of gene RBCL ...\n",
      "\t Completed\n",
      "\n",
      "Query File = 055130_89_S105_run905\n",
      "Counting species from top identity hits...\n",
      "\t Counting of gene RBCL ...\n",
      "\t Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    print('Counting species from top identity hits...')\n",
    "    \n",
    "    allprey = dict()\n",
    "    for gidx, gene_name in enumerate(gene_names):\n",
    "        print('\\t Counting of gene', gene_name, '...')\n",
    "        \n",
    "        path_blastin = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'-topIden.tsv'\n",
    "        ident = pd.read_csv(path_blastin, sep='\\t', index_col=0)\n",
    "\n",
    "        for idx, eachrow in ident.iterrows():\n",
    "            prey = eachrow['stitle'].split(';')[-1]\n",
    "            read_freq = eachrow['read_freq']\n",
    "\n",
    "            if prey not in allprey.keys():    allprey[prey] = [0]*len(gene_names)\n",
    "            allprey[prey][gidx] += read_freq\n",
    "\n",
    "    allprey = pd.DataFrame.from_dict(allprey, orient='index')\n",
    "    allprey.columns = gene_names\n",
    "    allprey.to_csv(query_file+'_blastResults/'+query_file+'_spcCount.tsv', sep='\\t')\n",
    "\n",
    "    print('\\t Completed\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
