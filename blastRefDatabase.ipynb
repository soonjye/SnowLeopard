{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build local BLAST database\n",
    "#### only need to build once. Ignore this part if you have performed this before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## change the name of genes that is going to be built into local database\n",
    "gene_names = ['COI', 'COX3', 'CYTB', 'ND2', 'ND4']\n",
    "\n",
    "for gene_name in gene_names:\n",
    "    path_fastafile = 'GbRefgene/gb'+gene_name+'.fasta'\n",
    "    dbtitle = gene_name+'ref'\n",
    "    !makeblastdb -in {path_fastafile} -parse_seqids -title {dbtitle} -dbtype nucl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Input Query filename and RefGene name\n",
    "fasta file of sequencing reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = 'SnowInput'  # change input files directory\n",
    "\n",
    "fastq_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "fastq_files = [path.splitext(x)[0] for x in fastq_files]\n",
    "\n",
    "print('Found %d sample files in directory: %s' % (len(fastq_files), mypath))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dereplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fastq_files = ['Deer32']\n",
    "#uncomment to manually input sample filenames without file extension\n",
    "\n",
    "for eachfastq in fastq_files:\n",
    "    !vsearch --derep_fulllength {mypath}/{eachfastq}.fa --output {mypath}/{eachfastq}_derep.fasta --sizeout --relabel uniq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_read_num = 1\n",
    "\n",
    "for eachfastq in fastq_files:\n",
    "    !vsearch --cluster_unoise {mypath}/{eachfastq}_derep.fasta --minsize {min_read_num} --unoise_alpha 2 --centroids {mypath}/{eachfastq}_freqfilt.fasta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_files = ['Deer32']\n",
    "# uncomment to manually change the filenames\n",
    "query_files = fastq_files\n",
    "\n",
    "gene_names = ['COI', 'COX3', 'CYTB', 'ND2', 'ND4']\n",
    "# change the list of genes that is gonna be blasted upon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Blast against Local Reference Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_identity = 98   ## change the cutoff\n",
    "\n",
    "\n",
    "for query_file in query_files:\n",
    "\n",
    "    !mkdir {query_file}_blastResults\n",
    "\n",
    "    path_blastin = mypath+'/'+query_file+'_freqfilt.fasta'\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        \n",
    "        path_fastafile = 'GbRefgene/gb'+gene_name+'.fasta'\n",
    "        path_blastout  = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'.tsv'\n",
    "        \n",
    "        blastx_cline = NcbiblastnCommandline(query=path_blastin, db=path_fastafile, evalue=0.001, line_length=alignment_length, perc_identity=percent_identity, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=path_blastout)\n",
    "        print('\\nBlasting '+query_file+' against', gene_name, 'database...', end=\" \")\n",
    "        t0 = datetime.now()\n",
    "        stdout, stderr = blastx_cline()\n",
    "        t1 = datetime.now()\n",
    "        print('Completed. Runtime: ', t1 - t0)\n",
    "\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parse Blast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_length = 50   ## cutoff of > 50 bp must be aligned\n",
    "\n",
    "\n",
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        blastn = pd.read_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'.tsv', sep='\\t', header=None)\n",
    "        blastn.columns = 'qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore'.split(' ')\n",
    "\n",
    "        reads = set(blastn['qseqid'])\n",
    "        print('Parsing blast ' + gene_name + ' result...')\n",
    "        print('\\t Number of reads with hits =', len(reads))\n",
    "\n",
    "\n",
    "        neitheridx = []\n",
    "        read_freq = []\n",
    "\n",
    "\n",
    "        ## filter hits if it belongs to human, bacteria, or fungi\n",
    "        for idx, eachrow in blastn.iterrows():\n",
    "            if (idx+1) % 100000 == 0:    print(idx)\n",
    "\n",
    "            m = re.search(';size=(\\d+)', eachrow['qseqid'])\n",
    "            read_count = m.group(1)\n",
    "            read_freq.append(read_count)\n",
    "\n",
    "            ## The presence of human, bacteria or fungi DNA could indicate contamination\n",
    "            ## The interpretation varies according to the samples\n",
    "            filtered_count = [0, 0, 0, 0]\n",
    "            if 'Homo_sapiens' in eachrow['stitle']:\n",
    "                filtered_count[0] += 1\n",
    "            elif 'Bacteria' in eachrow['stitle']:\n",
    "                filtered_count[1] += 1\n",
    "            elif 'Fungi' in eachrow['stitle']:\n",
    "                filtered_count[2] += 1\n",
    "            elif eachrow['length'] < alignment_length:\n",
    "                filtered_count[3] += 1\n",
    "            else:\n",
    "                neitheridx.append(idx)\n",
    "                \n",
    "\n",
    "        print(\"\\t Hit_Count: Homo_sapiens = %d \\t Bacteria = %d \\t Fungi = %d \\t Less than %dbp = %d\" % (filtered_count[0], filtered_count[1], filtered_count[2], alignment_length, filtered_count[3]))\n",
    "\n",
    "\n",
    "\n",
    "        ## retrieve frequency information\n",
    "        blastn['read_freq'] = read_freq\n",
    "        subset = blastn.loc[neitheridx, :]\n",
    "\n",
    "\n",
    "\n",
    "        ## retrieve read sequence from query_file\n",
    "        qseqids = list(set(list(subset['qseqid'])))\n",
    "        qseqdict = dict()\n",
    "\n",
    "        path_blastin = mypath+'/'+query_file+'_freqfilt.fasta'\n",
    "        zipfa = SeqIO.parse(path_blastin, 'fasta')\n",
    "        for read in zipfa:\n",
    "            if read.id in qseqids:\n",
    "                qseqdict[read.id] = read.seq\n",
    "\n",
    "        qseqs = []\n",
    "        for idx, eachrow in subset.iterrows():\n",
    "            qseqs.append(str(qseqdict[eachrow['qseqid']]))\n",
    "        subset['qseq'] = qseqs\n",
    "        subset.to_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'_filtered.tsv', sep='\\t')\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Top identity hit for each read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    print('Extract top hits of blast result')\n",
    "    \n",
    "    for gene_name in gene_names:\n",
    "        print('\\t Extracting gene', gene_name, '...')\n",
    "        \n",
    "        path_blastin = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'_filtered.tsv'\n",
    "        #if not path.exists(path_blastin):    continue\n",
    "        ident = pd.read_csv(path_blastin, sep='\\t', index_col=0)\n",
    "\n",
    "        qseqids = []\n",
    "        topidenIdx = []\n",
    "\n",
    "        prev_qseqid = ''\n",
    "\n",
    "        for idx, eachrow in ident.iterrows():\n",
    "            qseqid = eachrow['qseqid']\n",
    "\n",
    "            if qseqid != prev_qseqid:\n",
    "                prev_qseqid = qseqid\n",
    "                topident = eachrow['pident']\n",
    "                topidenIdx.append(idx)\n",
    "\n",
    "            else:\n",
    "                if eachrow['pident'] == topident:\n",
    "                    topidenIdx.append(idx)\n",
    "        \n",
    "        ident.loc[topidenIdx, :].to_csv(query_file+'_blastResults/'+query_file+'_blast'+gene_name+'-topIden.tsv', sep='\\t')\n",
    "\n",
    "    print('\\t Completed\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Diet Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_file in query_files:\n",
    "    print('Query File =', query_file)\n",
    "    print('Counting species from top identity hits...')\n",
    "    \n",
    "    allprey = dict()\n",
    "    for gidx, gene_name in enumerate(gene_names):\n",
    "        print('\\t Counting of gene', gene_name, '...')\n",
    "        \n",
    "        path_blastin = query_file+'_blastResults/'+query_file+'_blast'+gene_name+'-topIden.tsv'\n",
    "        ident = pd.read_csv(path_blastin, sep='\\t', index_col=0)\n",
    "\n",
    "        for idx, eachrow in ident.iterrows():\n",
    "            prey = eachrow['stitle'].split(';')[-1]\n",
    "            read_freq = eachrow['read_freq']\n",
    "\n",
    "            if prey not in allprey.keys():    allprey[prey] = [0]*len(gene_names)\n",
    "            allprey[prey][gidx] += read_freq\n",
    "\n",
    "    allprey = pd.DataFrame.from_dict(allprey, orient='index')\n",
    "    allprey.columns = gene_names\n",
    "    allprey.to_csv(query_file+'_blastResults/'+query_file+'_spcCount.tsv', sep='\\t')\n",
    "\n",
    "    print('\\t Completed\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
