{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build local BLAST database (only need to build once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 03/18/2021 03:15:39\n",
      "New DB name:   /home/soonjye/Documents/Snowleopard_Github/GenbankRef/gbCOI.fasta\n",
      "New DB title:  COIref\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 837845 sequences in 21.7983 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 03/18/2021 03:16:02\n",
      "New DB name:   /home/soonjye/Documents/Snowleopard_Github/GenbankRef/gbCOX3.fasta\n",
      "New DB title:  COX3ref\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 9470 sequences in 0.249865 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 03/18/2021 03:16:02\n",
      "New DB name:   /home/soonjye/Documents/Snowleopard_Github/GenbankRef/gbCYTB.fasta\n",
      "New DB title:  CYTBref\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 9977 sequences in 0.307142 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 03/18/2021 03:16:03\n",
      "New DB name:   /home/soonjye/Documents/Snowleopard_Github/GenbankRef/gbND2.fasta\n",
      "New DB title:  ND2ref\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 8787 sequences in 0.251188 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 03/18/2021 03:16:03\n",
      "New DB name:   /home/soonjye/Documents/Snowleopard_Github/GenbankRef/gbND4.fasta\n",
      "New DB title:  ND4ref\n",
      "Sequence type: Nucleotide\n",
      "Keep Linkouts: T\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 8820 sequences in 0.274948 seconds.\n"
     ]
    }
   ],
   "source": [
    "#!makeblastdb -in GenbankRef/gbCOI.fasta -parse_seqids -title COIref -dbtype nucl\n",
    "#!makeblastdb -in GenbankRef/gbCOX3.fasta -parse_seqids -title COX3ref -dbtype nucl\n",
    "#!makeblastdb -in GenbankRef/gbCYTB.fasta -parse_seqids -title CYTBref -dbtype nucl\n",
    "#!makeblastdb -in GenbankRef/gbND2.fasta -parse_seqids -title ND2ref -dbtype nucl\n",
    "#!makeblastdb -in GenbankRef/gbND4.fasta -parse_seqids -title ND4ref -dbtype nucl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Query file\n",
    "fasta file of sequencing reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file = 'CT-4.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Blast against Local Reference Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘CT-4.fa_blastResults’: File exists\n",
      "\n",
      "Blasting CT-4.fa against COI database... "
     ]
    }
   ],
   "source": [
    "!mkdir {query_file}_blastResults\n",
    "\n",
    "blastx_cline = NcbiblastnCommandline(query=query_file, db='GenbankRef/gbCOI.fasta', evalue=0.001, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=query_file+'_blastResults/blastCOI.tsv')\n",
    "print('\\nBlasting '+query_file+' against COI database...', end=\" \")\n",
    "t0 = datetime.now()\n",
    "stdout, stderr = blastx_cline()\n",
    "t1 = datetime.now()\n",
    "print('Completed. Runtime: ', t1 - t0, '\\n')\n",
    "                                     \n",
    "blastx_cline = NcbiblastnCommandline(query=query_file, db='GenbankRef/gbCOX3.fasta', evalue=0.001, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=query_file+'_blastResults/blastCOX3.tsv')\n",
    "print('Blasting '+query_file+' against COX3 database...', end=\" \")\n",
    "t0 = datetime.now()\n",
    "stdout, stderr = blastx_cline()\n",
    "t1 = datetime.now()\n",
    "print('Completed. Runtime: ', t1 - t0, '\\n')\n",
    "\n",
    "blastx_cline = NcbiblastnCommandline(query=query_file, db='GenbankRef/gbCYTB.fasta', evalue=0.001, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=query_file+'_blastResults/blastCYTB.tsv')\n",
    "print('Blasting '+query_file+' against CYTB database...', end =\" \")\n",
    "t0 = datetime.now()\n",
    "stdout, stderr = blastx_cline()\n",
    "t1 = datetime.now()\n",
    "print('Completed. Runtime: ', t1 - t0, '\\n')\n",
    "\n",
    "blastx_cline = NcbiblastnCommandline(query=query_file, db='GenbankRef/gbND2.fasta', evalue=0.001, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=query_file+'_blastResults/blastND2.tsv')\n",
    "print('Blasting '+query_file+' against ND2 database...', end =\" \")\n",
    "t0 = datetime.now()\n",
    "stdout, stderr = blastx_cline()\n",
    "t1 = datetime.now()\n",
    "print('Completed. Runtime: ', t1 - t0, '\\n')\n",
    "\n",
    "blastx_cline = NcbiblastnCommandline(query=query_file, db='GenbankRef/gbND4.fasta', evalue=0.001, outfmt=\"6 qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore\", out=query_file+'_blastResults/blastND4.tsv')\n",
    "print('Blasting '+query_file+' against ND4 database...', end =\" \")\n",
    "t0 = datetime.now()\n",
    "stdout, stderr = blastx_cline()\n",
    "t1 = datetime.now()\n",
    "print('Completed. Runtime: ', t1 - t0, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parse Blast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = CT-4.fa\n",
      "Parsing blastCOX3results \t Number of reads with hits = 14\n",
      "Parsing blastCYTBresults \t Number of reads with hits = 2439\n",
      "Parsing blastND2results \t Number of reads with hits = 189\n",
      "Parsing blastND4results \t Number of reads with hits = 193\n"
     ]
    }
   ],
   "source": [
    "barcodes = ['COI', 'COX3', 'CYTB', 'ND2', 'ND4']\n",
    "\n",
    "print('Query File =', query_file)\n",
    "for barcode in barcodes:\n",
    "    blastn = pd.read_csv(query_file+'_blastResults/blast'+barcode+'.tsv', sep='\\t', header=None)\n",
    "    blastn.columns = 'qseqid qlen sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore'.split(' ')\n",
    "    reads = set(blastn['qseqid'])\n",
    "    print('Parsing blast ' + barcode + ' result \\t Number of reads with hits =', len(reads))\n",
    "\n",
    "\n",
    "    punciaidx  = []\n",
    "    pantheridx = []\n",
    "    neitheridx = []\n",
    "    prev = ''\n",
    "    \n",
    "    ## filter hits if it belongs to human, bacteria, or fungi\n",
    "    for idx, eachrow in blastn.iterrows():\n",
    "        if (idx+1) % 100000 == 0:    print(idx)\n",
    "        \n",
    "        if 'Homo_sapiens' in eachrow['stitle']:    continue\n",
    "        if 'Bacteria' in eachrow['stitle']:    continue\n",
    "        if 'Fungi' in eachrow['stitle']:    continue\n",
    "\n",
    "        read = eachrow['qseqid']\n",
    "        if read != prev:\n",
    "            prev = read\n",
    "            if 'Panthera_uncia' in eachrow['stitle']:\n",
    "                punciaidx.append(idx)\n",
    "            elif 'Panthera' in eachrow['stitle']:\n",
    "                pantheridx.append(idx)\n",
    "            else:\n",
    "                neitheridx.append(idx)\n",
    "\n",
    "\n",
    "    ## filter hits if it is <98% identity and <50 bp overlap\n",
    "    subset = blastn.loc[punciaidx+pantheridx+neitheridx, :]\n",
    "\n",
    "    towrite= []\n",
    "    for idx, eachrow in subset.iterrows():\n",
    "        qlen   = eachrow[1]\n",
    "        alen   = eachrow[5]\n",
    "        pident = eachrow[4]\n",
    "        if alen > 50 and pident > 98:\n",
    "            towrite.append(idx)\n",
    "\n",
    "    if len(towrite) == 0:\n",
    "        print('Parsing blast ' + barcode + ' result \\t No hit that belongs to Panthera nor others with identity > 98%')\n",
    "        continue\n",
    "\n",
    "    ## retrieve read sequence from query_file\n",
    "    subset = subset.loc[towrite,:]\n",
    "    qseqids = list(set(list(subset['qseqid'])))\n",
    "    qseqdict = dict()\n",
    "\n",
    "    zipfa = SeqIO.parse(query_file, 'fasta')\n",
    "    for read in zipfa:\n",
    "        if read.id in qseqids:\n",
    "            qseqdict[read.id] = read.seq\n",
    "\n",
    "    qseqs = []\n",
    "    for idx, eachrow in subset.iterrows():\n",
    "        qseqs.append(str(qseqdict[eachrow['qseqid']]))\n",
    "    subset['qseq'] = qseqs\n",
    "    subset.to_csv(query_file + '_blastResults/blast' + barcode + '-iden98.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Top 1 hit for each read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = CT-4.fa\n",
      "Extract top hit of blast result (>98% identity & >50bp overlap)\n",
      "\tExtracting gene COI ...\n",
      "\tExtracting gene COX3 ...\n",
      "\tExtracting gene CYTB ...\n",
      "\tExtracting gene ND2 ...\n",
      "\tExtracting gene ND4 ...\n",
      "\tCompleted\n"
     ]
    }
   ],
   "source": [
    "barcodes = ['COI', 'COX3', 'CYTB', 'ND2', 'ND4']\n",
    "\n",
    "print('Query File =', query_file)\n",
    "print('Extract top hit of blast result (>98% identity & >50bp overlap)')\n",
    "for barcode in barcodes:\n",
    "    print('\\tExtracting gene', barcode, '...')\n",
    "    if not path.exists(query_file + '_blastResults/blast' + barcode + '-iden98.tsv'):    continue\n",
    "    ident = pd.read_csv(query_file + '_blastResults/blast' + barcode + '-iden98.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "    qseqids = []\n",
    "    best5 = []\n",
    "    best1 = []\n",
    "\n",
    "    for idx, eachrow in ident.iterrows():\n",
    "        qseqid = eachrow['qseqid']\n",
    "        if qseqid in qseqids:    continue\n",
    "\n",
    "        qseqids.append(qseqid)\n",
    "\n",
    "        subset = ident[ident['qseqid'] == qseqid]\n",
    "        subset = subset.sort_index('index')\n",
    "        \n",
    "        ## the index is generated by blastn output\n",
    "        ## the index is arranged according to qseqid, then e-value\n",
    "        [best1.append(x) for x in subset.index[:1]]\n",
    "\n",
    "    ident.loc[best1, :].to_csv(query_file + '_blastResults/blast' + barcode + '-top1.tsv', sep='\\t')\n",
    "\n",
    "print('\\tCompleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Prey Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query File = CT-4.fa\n",
      "Counting species from top1 result...\n",
      "\tCounting of gene COI ...\n",
      "\tCounting of gene COX3 ...\n",
      "\tCounting of gene CYTB ...\n",
      "\tCounting of gene ND2 ...\n",
      "\tCounting of gene ND4 ...\n",
      "\tComplete\n"
     ]
    }
   ],
   "source": [
    "allprey = dict()\n",
    "\n",
    "barcodes = ['COI', 'COX3', 'CYTB', 'ND2', 'ND4']\n",
    "\n",
    "print('Query File =', query_file)\n",
    "print('Counting species from top1 result...')\n",
    "for idx, barcode in enumerate(barcodes):\n",
    "    print('\\tCounting of gene', barcode, '...')\n",
    "    if not path.exists(query_file + '_blastResults/blast' + barcode + '-top1.tsv'):    continue\n",
    "    ident = pd.read_csv(query_file + '_blastResults/blast' + barcode + '-top1.tsv', sep='\\t', index_col=0)\n",
    "    \n",
    "    preys = list(ident.stitle)\n",
    "    preys = [x.split(';')[-1] for x in preys]\n",
    "\n",
    "    for prey in preys:\n",
    "        if prey not in allprey.keys():    allprey[prey] = [0]*len(barcodes)\n",
    "        allprey[prey][idx] += 1\n",
    "\n",
    "allprey = pd.DataFrame.from_dict(allprey, orient='index')\n",
    "allprey.columns = barcodes\n",
    "allprey.to_csv(query_file + '_blastResults/spc_count_.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "print('\\tCompleted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
